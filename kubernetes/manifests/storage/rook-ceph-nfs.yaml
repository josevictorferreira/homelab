apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    kubenix/k8s-version: '1.32'
    kubenix/project-name: ze-homelab
  name: homelab-nfs-export-apply
  namespace: rook-ceph
spec:
  backoffLimit: 3
  template:
    spec:
      containers:
        - command:
            - /bin/bash
            - -lc
            - "set -euo pipefail\nSUBVOL_GROUP='nfs-exports'\nSUBVOL_NAME='homelab-nfs'\n\
              FS='ceph-filesystem'\n\nCEPH_CONFIG=/etc/ceph/ceph.conf\nMON_CONFIG=/etc/rook/mon-endpoints\n\
              KEYRING_FILE=/etc/ceph/keyring\nendpoints=$(cat \"$MON_CONFIG\")\nmon_endpoints=$(echo\
              \ \"$endpoints\" | sed 's/[a-z0-9_-]\\+=//g')\nmkdir -p /etc/ceph\n\
              cat > \"$CEPH_CONFIG\" <<EOF\n[global]\nmon_host = $mon_endpoints\n\
              [client.admin]\nkeyring = $KEYRING_FILE\nEOF\nif   [ -f /var/lib/rook-ceph-mon/ceph-secret\
              \ ];  then ceph_secret=$(cat /var/lib/rook-ceph-mon/ceph-secret)\nelif\
              \ [ -f /var/lib/rook-ceph-mon/admin-secret ]; then ceph_secret=$(cat\
              \ /var/lib/rook-ceph-mon/admin-secret)\nelse echo \"No ceph admin secret\
              \ found\"; exit 2; fi\nif [ -f /var/lib/rook-ceph-mon/ceph-username\
              \ ]; then username=$(cat /var/lib/rook-ceph-mon/ceph-username); else\
              \ username=client.admin; fi\ncat > \"$KEYRING_FILE\" <<EOF\n[$username]\n\
              key = $ceph_secret\nEOF\n\nceph -c \"$CEPH_CONFIG\" mgr module enable\
              \ nfs || true\nceph -c \"$CEPH_CONFIG\" mgr module enable volumes ||\
              \ true\n\nceph -c \"$CEPH_CONFIG\" fs subvolumegroup create \"$FS\"\
              \ \"$SUBVOL_GROUP\" || true\nceph -c \"$CEPH_CONFIG\" fs subvolume create\
              \ \"$FS\" \"$SUBVOL_NAME\" \\\n  --group_name \"$SUBVOL_GROUP\" --size\
              \ 0 --uid 2002 --gid 2002 --mode 2775 || true\n\nSUBVOL_PATH=\"$(ceph\
              \ -c \"$CEPH_CONFIG\" fs subvolume getpath \"$FS\" \"$SUBVOL_NAME\"\
              \ --group_name \"$SUBVOL_GROUP\")\"\n\ncluster='homelab-nfs'\n\nawk\
              \ -v newval=\"$SUBVOL_PATH\" '{\n  gsub(/\"path\":[[:space:]]*\"[^\"\
              ]*\"/, \"\\\"path\\\": \\\"\" newval \"\\\"\");\n  print\n}' /etc/ganesha/export.json\
              \ > /tmp/export.json\n\nceph -c \"$CEPH_CONFIG\" nfs export apply \"\
              $cluster\" -i /tmp/export.json\n\nceph -c \"$CEPH_CONFIG\" nfs export\
              \ info \"$cluster\" \"/homelab\"\n"
          image: quay.io/ceph/ceph:v19
          name: apply
          volumeMounts:
            - mountPath: /etc/rook
              name: mon-endpoints
            - mountPath: /etc/ceph
              name: ceph-config
            - mountPath: /var/lib/rook-ceph-mon
              name: ceph-admin-secret
              readOnly: true
            - mountPath: /etc/ganesha
              name: homelab-nfs-export
              readOnly: true
      restartPolicy: OnFailure
      serviceAccountName: rook-ceph-default
      volumes:
        - configMap:
            items:
              - key: data
                path: mon-endpoints
            name: rook-ceph-mon-endpoints
          name: mon-endpoints
        - emptyDir: {}
          name: ceph-config
        - name: ceph-admin-secret
          secret:
            secretName: rook-ceph-mon
        - configMap:
            name: homelab-nfs-export
          name: homelab-nfs-export
  ttlSecondsAfterFinished: 3600
---
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    kubenix/k8s-version: '1.32'
    kubenix/project-name: ze-homelab
  name: homelab-nfs-ganesha-conf-patch
  namespace: rook-ceph
spec:
  backoffLimit: 2
  template:
    spec:
      containers:
        - args:
            - "set -euo pipefail\nNS='rook-ceph'\nCLUSTER='homelab-nfs'\nCM=\"\"\n\
              \nexport PATH=/opt/bitnami/kubectl/bin:$PATH\n\nfor i in {1..10}; do\n\
              \  if [ -n \"$CM\" ]; then break; fi\n  echo \"Waiting for rook-ceph-nfs\
              \ ConfigMap...\"\n  sleep 6\n  CM=\"$(kubectl -n \"$NS\" get cm -l app=rook-ceph-nfs\
              \ -o name | grep -i rook-ceph | head -n1 || true)\"\ndone\n\n[ -z \"\
              $CM\" ] && { echo \"ERROR: rook-ceph ganesha ConfigMap not found\";\
              \ exit 1; }\n\necho \"Patching $CM in $NS\"\n\nkubectl -n \"$NS\" patch\
              \ \"$CM\" --type merge -p '{\"data\":{\"config\": \"'\"$(cat /tmp/ganesha.conf\
              \ | sed 's/\"/\\\\\"/g' | tr '\\n' ' ' | tr  '\\t' ' ')\"'\"}}'\n\n\
              DEP=\"$(kubectl -n \"$NS\" get deploy -l app=rook-ceph-nfs,rook_cluster=\"\
              $CLUSTER\",ceph_daemon_type=nfs -o name | head -n1 || true)\"\nif [\
              \ -z \"$DEP\" ]; then\n  DEP=\"$(kubectl -n \"$NS\" get deploy -l app=rook-ceph-nfs\
              \ -o name | head -n1 || true)\"\nfi\n[ -z \"$DEP\" ] && { echo \"WARN:\
              \ deployment not found; skipping restart\"; exit 0; }\n\nkubectl -n\
              \ \"$NS\" rollout restart \"$DEP\"\nkubectl -n \"$NS\" rollout status\
              \  \"$DEP\"\necho \"Done.\"\n"
          command:
            - /bin/bash
            - -lc
          image: bitnami/kubectl:1.30
          name: patch
          volumeMounts:
            - mountPath: /tmp
              name: homelab-nfs-ganesha-config
              readOnly: true
      restartPolicy: OnFailure
      serviceAccountName: rook-ceph-default
      volumes:
        - configMap:
            name: homelab-nfs-ganesha-config
          name: homelab-nfs-ganesha-config
  ttlSecondsAfterFinished: 3600
---
apiVersion: ceph.rook.io/v1
kind: CephNFS
metadata:
  annotations:
    kubenix/k8s-version: '1.32'
    kubenix/project-name: ze-homelab
  name: homelab-nfs
  namespace: rook-ceph
spec:
  server:
    active: 1
    placement:
      tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
    resources:
      limits:
        memory: 512Mi
      requests:
        cpu: 50m
        memory: 64Mi
---
apiVersion: v1
data:
  export.json: '{"access_type":"RW","clients":[{"access_type":"RW","addresses":["10.10.10.0/24"],"squash":"no_root_squash"}],"export_id":1,"fsal":{"fs_name":"ceph-filesystem","name":"CEPH"},"manage_gids":true,"path":"/exported/path","protocols":[4],"pseudo":"/homelab","sectype":["sys"],"security_label":false,"squash":"no_root_squash","transports":["TCP"]}'
kind: ConfigMap
metadata:
  annotations:
    kubenix/k8s-version: '1.32'
    kubenix/project-name: ze-homelab
  name: homelab-nfs-export
  namespace: rook-ceph
---
apiVersion: v1
data:
  ganesha.conf: "NFS_CORE_PARAM {\n  Enable_NLM = false;\n  Enable_RQUOTA = false;\n\
    \  Protocols = 4;\n  NFS_Port = 2049;\n  Bind_Addr = 0.0.0.0;\n}\n\nMDCACHE {\n\
    \  Dir_Chunk = 0;\n}\n\nNFSv4 {\n  Graceless = false;\n  Delegations = false;\n\
    \  Minor_Versions = 0;\n  Allow_Numeric_Owners = true;\n  Only_Numeric_Owners\
    \ = false;\n}\n\nNFS_KRB5 { Active_krb5 = false; }\n\nEXPORT_DEFAULTS {\n  Attr_Expiration_Time\
    \ = 0;\n  Protocols = 4;\n  Transports = TCP;\n  Access_Type = RW;\n  Squash =\
    \ No_Root_Squash;\n  Manage_Gids = false;\n}\n\nRADOS_KV {\n  ceph_conf = \"/etc/ceph/ceph.conf\"\
    ;\n  userid = \"nfs-ganesha.homelab-nfs.a\";\n  nodeid = \"homelab-nfs.a\";\n\
    \  pool = \".nfs\";\n  namespace = \"homelab-nfs\";\n}\n\nCEPH { Ceph_Conf = \"\
    /etc/ceph/ceph.conf\"; }\n\nEXPORT {\n  Export_Id = 1;\n  Path = \"/\";\n  Pseudo\
    \ = \"/homelab-storage\";\n  Protocols = 4;\n  Transports = TCP;\n  Access_Type\
    \ = RW;\n  Squash = No_Root_Squash;\n  Manage_Gids = true;\n  Sectype = sys;\n\
    \n  FSAL {\n    Name = \"CEPH\";\n    Filesystem = \"ceph-filesystem\";\n    User_Id\
    \ = \"nfs-ganesha.homelab-nfs.a\";\n  }\n\n  CLIENT {\n    Clients = 10.10.10.0/24;\n\
    \    Protocols = 4;\n    Squash = No_Root_Squash;\n  }\n\n  LOG {\n    Default_Log_Level\
    \ = FULL_DEBUG;\n  }\n}\n\n"
kind: ConfigMap
metadata:
  annotations:
    kubenix/k8s-version: '1.32'
    kubenix/project-name: ze-homelab
  labels:
    app: rook-ceph-nfs
    ceph_daemon_type: nfs
    rook_cluster: homelab-nfs
  name: homelab-nfs-ganesha-config
  namespace: rook-ceph
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kubenix/k8s-version: '1.32'
    kubenix/project-name: ze-homelab
    lbipam.cilium.io/ips: 10.10.10.150
    lbipam.cilium.io/sharing-key: homelab-nfs
  name: homelab-nfs
  namespace: rook-ceph
spec:
  externalTrafficPolicy: Cluster
  ports:
    - name: nfs-tcp
      port: 2049
      protocol: TCP
      targetPort: 2049
    - name: nfs-udp
      port: 2049
      protocol: UDP
      targetPort: 2049
  selector:
    app: rook-ceph-nfs
    ceph_daemon_type: nfs
  type: LoadBalancer
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  annotations:
    kubenix/k8s-version: '1.32'
    kubenix/project-name: ze-homelab
  name: homelab-nfs-ganesha-conf-patch-role
  namespace: rook-ceph
rules:
  - apiGroups:
      - ''
    resources:
      - configmaps
    verbs:
      - get
      - list
      - watch
      - patch
  - apiGroups:
      - apps
    resources:
      - deployments
    verbs:
      - get
      - list
      - watch
      - update
      - patch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  annotations:
    kubenix/k8s-version: '1.32'
    kubenix/project-name: ze-homelab
  name: homelab-nfs-ganesha-conf-patch-rb
  namespace: rook-ceph
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: homelab-nfs-ganesha-conf-patch-role
subjects:
  - kind: ServiceAccount
    name: rook-ceph-default
    namespace: rook-ceph
